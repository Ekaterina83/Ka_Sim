!pip install -q findspark

# Настройка переменных окружения


import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.3-bin-hadoop2.7"

# Получаем экземпляр спарка

import findspark
findspark.init()
from pyspark.sql import SparkSession

spark = SparkSession.builder.master("local[*]").getOrCreate()

# Загрузим данные
df = spark.read.csv('train_house_prices.csv', header=True)

df.printSchema()

df.show(15)

df.columns

df.select('SalePrice').show(15)

df.select(df['SalePrice'] * 2).show(15)

df.filter(df['SalePrice'] > 300000).count()

from pyspark.ml.stat import Correlation
from pyspark.ml.feature import VectorAssembler

from pyspark.ml.linalg import Vectors
from pyspark.ml.stat import Correlation



